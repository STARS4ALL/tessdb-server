NUEVO TESSDB
============

* rescribir el subpaquete service para que solo haya que importar "application" como twisted
* Implementar Prodcuer/Consumer
- MQTT Peoducer > Filtro (Producer/Consumer) => Database(consumer)
- No se si hará falta el pypubsub para otros eventos relacionados
* leer Config.ini en el main y con fichero a la antigua. Se sigu eneecsiatndo el pause/resume y reload
* Database versioning (tabla config_t) para implementa versiones
* En cada servicio consumer habra una Deferred queue.
   * Si la BD se satura, pausar hacia atras, hasta que se tiren paquetes de MQTT
* paquete dbase con subpaquetes sqlite3 y postgres
- en sqlite3 usar el DAO que me he inventado
- hay que hgacer escritures executemany ewn la BD para mejorar prestaciones ¿es solo sqlite3?
  - otra cola interna para escribir de golpe con executemany
* nueva versiond de MD para TESS-4C
 - la tabla de hechos, añadimos columnas a pelo
 - una nueva tabla de detalle tess4c_t con una referencia al tess_id de la tess_t
 De esta manera los informes siguen funcionando como siempre y se podar sacar info nueva
 con queries espèciales
 * comandos al subdirectorio scripts en lugar de /usr/local/bin
* Calyx
- ver que version de python3 tiene
- instalar un venv de prieba y alli dentro twisted. A ver si nos llevamos sorpresas con la ultima version




Prioridad Alta
==============


Prioridad media
===============

1) Nueva tabla observer_t, con atributos gestionados de email y organization

CREATE TABLE IF NOT EXISTS observer_t
(
  observer_id  INTEGER PRIMARY KEY,
  name         TEXT NOT NULL, -- Family name
  nickname     TEXT,          -- nickname (i,e. nick in epicollect5)
  organization TEXT,          -- i.e. AstroHenares
  email        TEXT           -- contact e-mail 
  valid_since  TEXT  DEFAULT (strftime('%Y-%m-%dT%H:%M:%S','now')), -- timestamp since organization value is valid
  valid_until  TEXT  DEFAULT '2999-12-31T23:59:59', 
  valid_state  TEXT  DEFAULT 'Current'
  -- Alternate key would be PRIMARY KEY (name)
);


Prioridad baja
==============

*) Batch load utility

- Al final tiene que quedar un fichero SQL con inserciones para que sea muy efeciente

- Funcion (tstamp,name) => tess_id, location_id, observer_id
Esta funcion tiene que ser calculada por agregados diarios, group by (date) y ver si ha habido
cambios en location_id y observer_id empelando min() y max(). 
No podemos estar llamandola por cada muestra que queremos insertar

aqui es importanet tambien usar la fecha de la muestra para ver cambios de nombre y de zp, que dan lugar a nuevos tess_id 
y nuevas asociaciones

- Tambien se puede calcular el epriodo de envío por día y fijándonos en  3 números de secuencia consecutivos


*) Tess muticanal

La estrategia para soportar e TESS multicanal implicara muy pocos cambios en el modelo de datos:
- Cada fila de la tabla tess_t indicará un canal
- en cada canal hay que poner los siguientes datos adicionales, específicos suyos:
 +) los nombres de los angulos de inclinacion de los sensores respecto a la caja del instrumento (¿cuantos ángulos, qué nombres?) REALMENTE NO ES NECESARIO TENIENDO EL CHANNEL NUMBER
- cada medida de tess_readings indicaró la medida de un canal
- Hay que introducir la dimension adicional de orientación para tener datos de la orientación delos distintos sensores hacia el cielo. Por defecto, en los TESS monocanales, se asume el Zenit.
  +) Número de angulos: 3. ¿Nombres como en aviacion?
    Yaw   = Azimut
    Pitch = Altura
    Roll  = Inclinacion lateral Este-Oeste

*) Estudiar si merece la pena poner nuevas constraints UNIQUE NOT NULL a tess_t.name y tess_t.mac_address
*) Embeber servidor web de twisted.

NOTE
====

He averiguado que los descartes son por el 'retained' flag

ADDENDUM
========
